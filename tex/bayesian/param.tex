\section{Bayesian Inference of Material Parameters}
\label{sec:bayesian:param}

In what follows, we first describe a Bayesian formulation of the estimation problem in terms of a posterior distribution. Next, we discuss how to use the posterior for point estimation in a maximum a-posteriori (MAP) framework, and how the Markov-Chain Monte Carlo (MCMC) methods for Bayesian inference extend the point estimate approach by sampling from the posterior.


\subsection{Bayesian formulation}
\label{ssec:point_sec}

We treat the procedural model parameters $\btheta$ as random variables with corresponding probability distributions.

We first introduce a \emph{prior} probability distribution $p(\btheta)$ of the parameters, reflecting our pre-existing beliefs about the likelihood values of the unknown parameters. For example, for most material categories, we know what range the albedo color and roughness coefficients of the material should typically be in.

Further, we model the $\approx$ operator from Eq. \eqref{eq:approx} as an error distribution. Specifically, we postulate that the difference between the simulated image summary $\summ(f(\btheta, \bz))$ and the target image summary $\summ(\target)$ follows a known probability distribution.
In practice, we use a (multi-variate) normal distribution with zero mean and the covariance $\bsigma_e$:
\begin{equation}
	\summ(f(\btheta, \bz)) - \summ(\target) \sim \mathcal{N}(0, \bsigma_e).
\end{equation}
Our experiments indicate that this simple error distribution works well in practice, and we regard $\bsigma_e$ as a hyper-parameter and set it manually.

We also have multiple options in handling the random vector $\bz$. While it is certainly theoretically possible to estimate it, we are not really interested in its values;  we find it simpler and more efficient to simply choose $\bz$ randomly, fix it, and assume it known during the process of estimating the ``interesting'' parameters $\btheta$.

Under these assumptions, according to the Bayes theorem, we can write down the posterior probability of parameters $\btheta$, conditional on the known values of $\target$ and $\bz$, as:
\begin{equation} 
	\label{eq:posterior}
	p(\btheta | \target, \bz) \propto \mathcal{N}\left[\summ(f(\btheta, \bz)) - \summ(\target); 0, \bsigma_e\right] p(\btheta),
\end{equation}
where the right side does not need to be normalized; the constant factor has no effect on parameter estimates.
For numerical stability, we compute the negative log posterior, viz. $-\log p(\btheta | \target, \bz)$, in practice. Equation~\eqref{eq:posterior} also holds when $\btheta$ involves discrete parameters, as long as the prior is properly defined as a product of a continuous pdf $p(\btheta_c)$ and a discrete probability $p(\btheta_d)$.

\subsection{Point estimate of parameter values}

A point estimate of the parameter vector can be modeled in the maximum a-posteriori (MAP) framework. We simply estimate the desired parameter values $\btheta$ as the maximum of the posterior pdf $p(\btheta | \target, \bz)$ given by Eq. \eqref{eq:posterior}. For continuous $\btheta$, this problem can be solved using standard non-linear optimization algorithms. In the presence of discrete parameters, there is no single accepted solution. While various heuristics could be used, our sampling approach described below provides a cleaner solution to discrete parameter estimation.

\subsection{Markov-Chain Monte Carlo Sampling of the Posterior}
\label{ssec:bayesian}

Although the point estimate approach gives satisfactory results in many cases, it is not without problems. For example, since a perfect match between a procedural material and a photograph is generally impossible, it can be desirable to have a set of imperfect matches for the user to choose from. Further, there could be an entire subset of the parameter space giving solutions of approximately equivalent fit under the target view and lighting; however, these may look quite different from each other in other configurations, and a user may want to explore those differences. Lastly, with the presence of discrete parameters, it is not obvious how to solve the maximization in Eq. \eqref{eq:posterior} efficiently.

In this chapter, we use the well-known technique of full Bayesian inference, sampling the posterior pdf defined in Eq.~\eqref{eq:posterior} using Markov-Chain Monte Carlo (MCMC) techniques, specifically Metropolis-Hasting (MH)~\cite{hastings1970monte}, Hamiltonian Monte Carlo (HMC) \cite{betancourt2017conceptual}, and Metropolis-adjusted Langevin algorithm (MALA)~\cite{roberts1996exponential}. While well explored in statistics and various scientific fields, to our knowledge, this technique has not been used for the inference of material parameters.

The goal of the sampling is to explore the posterior with many (typically thousands or more) samples, each of which represents a material parameter vector consistent with the target image. Plotting these samples projected into two dimensions (for a given pair of parameters) gives valuable insight into similarity structures. Furthermore, interactively clicking on samples and observing the predicted result can help a user to quickly zoom in on a preferred solution, which an automatic optimization algorithm is fundamentally incapable of.

\input{tex/bayesian/alg/sample}

Algorithm \ref{alg:bayesian:sample} summarizes our MCMC sampling process. At each iteration, we mutate either the continuous parameters (with probability $\pc$) or the discrete ones (with probability $1 - \pc$).
For the former case, we utilize the gradient of the log pdf with respect to $\btheta_c$ to efficiently obtain a new proposal $\btheta_c'$ (Line \ref{alg:line:malaSample}).
Our implementation uses MALA for this process, although HMC could also work.
For the latter case, we obtain a new proposal $\btheta_d'$ of the discrete parameters, currently by uniformly sampling their joint probability mass function (Line \ref{alg:line:mhSample}).
Upon obtaining a full proposal, we use the standard Metropolis-Hasting rule (Line \ref{alg:line:mhAccRej}) to stochastically select the new sample $(\btheta_c^{(t + 1)}, \btheta_d^{(t + 1)})$ by either accepting the newly proposed $(\btheta_c', \btheta_d')$ or (rejecting the proposal and) keeping the previous sample $(\btheta_c^{(t)}, \btheta_d^{(t)})$.
