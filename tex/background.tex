\chapter{Background}
\label{cpt:background}

In this chapter, we briefly review some background knowledge closely related to this dissertation. Firstly, we recap the fundamental light transport theory and Bidirectional Reflectance Distribution Function (BRDF). Then we introduce Maxwells' equation in wave optics. Finally we talk about some concepts in Markov Chain Monte Carlo (MCMC) methods. 

\section{Light Transport}
Radiometry is a set of techniques for measuring electromagnetic radiation, and we use is to measure the energy of visible lights in nowadays renderings. First we list some important Radiometric quantities and then describe rendering equations in the following sections.

\begin{table}[!ht]
	\centering
	\caption[List of radiometry quantities]{\label{tab:background:notation}
		List of radiometry quantities.
	}
	\begin{tabular}{cccc}
		Quantity & Symbol & Unit & Notes \\
		\hline
		\multirow{2}{*}{Flux(Power)} & \multirow{2}{*}{$\Phi$} & \multirow{2}{*}{W} & Radiant energy emitted, reflected, \\
		 & & & transmitted or received, per unit time. \\[0.2em]
		Irradiance & $E$ & $W/m^2$ & Flux received by a surface per unit area. \\[0.2em]
		Radiance & $L$ & $W/(Sr\cdot m^2)$ $^*$ & Flux per unit solid angle per unit projected area. \\
		\hline
		\multicolumn{3}{l}{\footnotesize{$^*$ watt per steradian per square meter.}}	
	\end{tabular}
\end{table}

\subsection{Surface rendering equation}
To render photorealistic image, a key concept is to simulate light transport, which models the light interaction between camera/eyes, scene objects and lightsource. For any point in the scene, we want to know its spectral radiance $\Lo(\bmr,\bmomegao,\lambda,t)$ of wavelength $\lambda$ directed outward along direction $\bmomegao$ at time $t$, from a particular position $\bmr$. For simplisity, the commonly used \emph{rendering equation} (RE) \cite{kajiya1986rendering} for surface have two assumptions: geometric optics only and steady state. Therefore, we reformulate the light radiance as a $5D$ function of position ($\bmr$) and direction ($\bmomegao$), the outgoing radiance ($\Lo$) is the sum of the emitted radiance ($\Le$) and the reflected radiance ($\Lr$). The reflected radiance itself is the sum of all directions of incoming radiance ($\Li$) weighted by the surface reflection ($\fr$) and cosine of incident angle.
\begin{equation}     	
	\begin{aligned}
		\Lo(\bmr,\bmomegao) &= \Le(\bmr,\bmomegao) + \Lr(\bmr,\bmomegao) \\
		&= \Le(\bmr,\bmomegao) + 
		\int_{\bbSS} \Li(\bmr,\bmomegai) \fr(\bmr,\bmomegai\rightarrow\bmomegao) \EV{\bmn(\bmr),\bmomegai} \intd \bmomegai
	\end{aligned}
\end{equation}
Note that, $\bmomegao$ is the direction of the outgoing light, and $\bmomegai$ is the negative direction of the incoming light. 

The rendering equation can fully model the light transport in a space without any participating media. It is popular to expand this integral equation to \emph{path integral formulation} and solve it using Monte Carlo methods (see Veach's thesis 
\cite{veach1997metropolis}).


\subsection{Volume rendering equation}
When light travels in a participation medium (e.g., smoke, marble and skin), we use \emph{radiative transfer equation} (RTE) \cite{chandrasekhar1960radiative} to describe how the radiance changes by four types of interaction events: emission, absorption, out-scattering, and in-scattering.
\begin{equation}
	\begin{aligned}
		(\bmomegao\cdot\nabla) \Lo(\bmr,\bmomegao) &= 
		\overbrace{\sigmas(\bmr,\bmomegao) \int_{\bbSS} \Li(\bmr,\bmomegai)\fp(\bmr,\bmomegai\rightarrow\bmomegao) \intd\bmomegai}^{\text{a) In-scattering}} \\
		& \overbrace{-\sigmas(\bmr,\bmomegao)\Lo(\bmr,\bmomegao)}^{\text{b) Out-scattering}}
		\overbrace{-\sigmaa(\bmr,\bmomegao)\Lo(\bmr,\bmomegao)}^{\mathrm{c) Absorption}}
		\overbrace{+\Le(\bmr,\bmomegao)}^{\mathrm{d) Emission}}
	\end{aligned}
\end{equation}
The RTE is a integro-differential equation which can be derived via conservation of energy. Briefly, the RTE states that a beam of light loses energy through divergence and extinction (including both absorption (c) and scattering (b) away from the beam) and gains energy from light sources (d) in the medium and scattering (a) directed towards the beam. Same as RE, coherence, polarization and light speed are neglected. Optical properties such as refractive index ($m$), absorption coefficient ($\sigmaa$), scattering coefficient ($\sigmas$) are taken as time-invariant but may vary spatially. In addition, we define the extinction coefficient $\sigmat = \sigmaa + \sigmas$, and the ratio between $\sigmas$ and $\sigmat$ controls the fraction of radiant energy not being absorbed at each scattering and is also known as the single-scattering albedo ($a$). We use phase functions $\fp(\bmomegai\rightarrow\bmomegao)$ to describe the directional distribution of light scattered in a medium.

It is desirable to rewrite the RTE as an integral equation, which can them be solved numerically using Monte Carlo methods (see Veach's thesis 
\cite{veach1997metropolis}). 

\section{Scattering Distribution Function}
In RE and RTE, an important term is still missing. When light hit a surface or a particle in the medium, how does the light scatter, or in other words, redistribute both in energy and direction? To model this scattering effect, we use \emph{bidirectional reflectance distribution function} (BRDF) for surface interaction and \emph{phase function} (PF) for light scattering in a medium.

\subsection{Bidirectional reflectance distribution function (BRDF)}
The BRDF is a 4-$D$ function that defines how light is reflected at an opaque surface. 
\begin{equation}
	\fr(\bmomegai\rightarrow\bmomegao) = \frac{\intd \Lo(\bmomegao)}{\intd \Ei(\bmomegai)}
	= \frac{\intd\Lo(\bmomegao)}{\Li(\bmomegai)\EV{\bmn,\bmomegai}\intd\bmomegai}
\end{equation}
The function takes an incoming light direction $\bmomegai$, and outgoing direction $\bmomegao$, and returns the ratio of reflected radiance ($\Lo$) exiting along $\bmomegao$ to the irradiance incident ($\Li$) on the surface from direction $\bmomegai$. Each direction $\bmomega$ is itself parameterized by azimuth angle $\varphi$ and polar angle $\theta$. $\bmn$ is the (macro) surface normal.

Physically based BRDFs have several properties, including,

Positivity: 
\begin{equation}
	\fr(\bmomegai\rightarrow\bmomegao) \geq 0
\end{equation}
Reciprocity:
\begin{equation}
	\fr(\bmomegai\rightarrow\bmomegao) = \fr(\bmomegao\rightarrow\bmomegai)
\end{equation}
Conserving energy:
\begin{equation}
	\forall\bmomegao, \int_{\bbSS} \fr(\bmomegai\rightarrow\bmomegao) \EV{\bmn,\bmomegai} \leq 1
\end{equation}

Some basic BRDFs and the BRDFs used in this dissertation are listed below:

\paragraph{Lambertian BRDF} distribute the incident energy equally towards all the outgoing directions and give a diffuse appearance.
\begin{equation}
	\fr(\bmomegai\rightarrow\bmomegao) = \kd
\end{equation}
where $\kd$ is the albedo or absorption of light which will introducing the color.

\paragraph{Phong and Blinn-Phong BRDF} adds a specular component to introduce glossy effect.
\begin{equation}
	\fr(\bmomegai\rightarrow\bmomegao) = \kd + \ks({\bmomegai}_\mathrm{r} \cdot \bmomegao)^n
\end{equation}
where ${\bmomegai}_\mathrm{r}$ is the reflection of incident light and larger $n$ will increase the glossiness of the material. 

\paragraph{Microfacet BRDF} is the state-of-the-art model which is widely used in all kinds of renderers. The microfacet theory assumes that all surfaces are formed by tiny microfacets that are perfectly specular that reflect rays like perfectly smooth mirrors.
\begin{equation}
	\fr(\bmomegai\rightarrow\bmomegao) = 
	\frac{F(\bmomegai, \bmh) G(\bmomegai,\bmomegao,\bmh) D(\bmh)}
	{4\EV{\bmn,\bmomegai}\EV{\bmn,\bmomegao}}
\end{equation}
where $\bmh$ is the half vector that $\bmh=(\bmomegai+\bmomegao)/2$. The first component $F$ is Fresnel term, $G$ is the geometry term (shading factor) and $D$ is \emph{normal distribution function} (NDF) which indicate the distribution of microfacets normals. With the change of statistics of the micro-geometry, the macro-properties changes accordingly.
All NDF should follow:
\begin{equation}
	\int_{\bbSS} D(\bmh)\EV{\bmn,\bmh} \intd\bmh = 1
\end{equation}
There're two forms of NDF we used in most of the papers, \emph{Beckmann} and \emph{GGX}.

BRDF is a special case for opaque surface with reflection only. It can be extend to \emph{bidirectional transmittance distribution function} (BTDF) for  opposite side of the surface, and \emph{bidirectional scattering distribution function} (BSDF), a superset and generalization of BRDF and BTDF.

%\emph{Beckmann}:
%\begin{equation}
%	D(\bmh) = \frac{1}{\pi\alpha^2\cos^4\theta}\Exp^{-\frac{\tan^2\theta}{\alpha^2}}
%\end{equation}
%
%\emph{GGX}:
%\begin{equation}
%	D(\bmh) = \frac{\alpha^2}{\pi((\alpha^2-1)\cos^2\theta+1)^2}
%\end{equation}


\paragraph{Spatially varying BRDF}
The \emph{spatially varying BRDF} (SVBRDF) is a 6-$D$ function, $\fr(\bmr,\bmomegai,\bmomegao)$, where $\bmr$ describes a 2D location over an object's surface.


\subsection{Phase function}
Phase function is usually parameterized as a function of the angle ($\theta$) between $\bmomegai$ and $\bmomegao$, to model how light scattered in medium. A common phase function is \emph{Henyey-Greenstain} (HG) phase function with parameter $-1<g<1$:
\begin{equation}
	\fp(\theta,g) = \frac{1}{4\pi}
	\frac{1-g^2}
	{(1+g^2-2g\cos\theta)^{3/2}}
\end{equation}


\section{Maxwell Equations}

\subsection{Basic operators and notation}

The differential operator given in Cartesian coordinates $\{x,y,z\}$: 
\begin{equation}
	\nabla = \frac{\partial}{\partial x}\mathbf{i} + \frac{\partial}{\partial y}\mathbf{j} + \frac{\partial}{\partial z}\mathbf{k}
\end{equation}
For a scalar function $f(x,y,z)$ and a vector field $\bfF(x,y,z) = f_1(x,y,z)\mathbf{i} + f_2(x,y,z)\mathbf{j} + f_3(x,y,z)\mathbf{k}$, we have,

Gradient:
\begin{equation}
	\nabla f = \frac{\partial f}{\partial x}\mathbf{i} + \frac{\partial f}{\partial y}\mathbf{j} + \frac{\partial f}{\partial z}\mathbf{k}
\end{equation}
Divergence: 
\begin{equation}
	\Div\bfF = \frac{\partial f_1}{\partial x} + \frac{\partial f_2}{\partial y} + \frac{\partial f_3}{\partial z}
\end{equation}
Curl: 
\begin{equation}
	\Curl\bfF = \left|
	\begin{array}{ccc}
		\mathbf{i} & \mathbf{j} & \mathbf{k} \\
		\frac{\partial}{\partial x} & \frac{\partial}{\partial y} & \frac{\partial}{\partial z} \\
		f_1 & f_2 & f_3
	\end{array}
	\right|
\end{equation}	
Laplace operator: $\nabla^2 f = \Div(\nabla f)$

Curl of Curl: 
	$\Curl(\Curl\bfF) = \nabla(\Div\bfF) - \Div(\nabla\bfF) = - \Div(\nabla\bfF) = -\nabla^2\bfF$


\subsection{Derivation}

\begin{table}[!ht]
	\centering
	\caption[List of Maxwell notations]{\label{tab:background:notation2}
		List of Maxwell notations.
	}
	\begin{tabular}{ccl}
		Symbol & Unit & Notes \\
		\hline
		$\bfE$ & $V/m$      & Electric field \\
		$\bfH$ & $A/m$      & Magnetic field \\
		$\bfD$ & $C/m^2$    & Electric displacement \\
		$\bfB$ & $Wb/m^2$   & Magnetic induction \\
		$\bfJ$ & $A/m^2$    & Electric current density \\
		$\bfM$ &            & Magnetic current density \\
		$\bfP$ &            & Electric polarization \\
		$\rho$ & $C/m^3$    & Electric charge density \\
		$q$    & $Wb/m^3$   & Magnetic charge density \\
		$\varepsilon_0$     & $F/m$ & Electric permittivity of free space ($=8.854187817\times10^{-12}$) \\
		$\mu_0$             & $H/m$ & Magnetic permeability of free space ($=4\pi\times10^{-7}$) \\
	\end{tabular}
\end{table}

The mathematical description of Maxwell’s equations are \cite{bohren2008absorption}:
\begin{equation}
	\begin{aligned}
		\Div\bfD  &= \rho & & & & & \Div\bfB &= 0 \\
		\Curl\bfE &= -\frac{\partial\bfB}{\partial t} & & & & & 
		\Curl\bfH &= \mathbf{J} + \frac{\partial\bfD}{\partial t}
  \end{aligned}
\end{equation}
where, $\bfD = \varepsilon_0\bfE + \bfP$ and 
	$\bfH = \frac{1}{\mu_0}\bfB - \bfM$.

In free space, the polarization ($\bfP$) and magnetization ($\bfM$) vanish identically. And if there is no Electric charge density ($\rho$) and Electric current density ($\mathbf{J}$), we rewrite \textit{Maxwell equation} in the form of $\bfE$ and $\bfH$,
\begin{equation}
	\begin{aligned}
		\Div\bfE  &= 0 & & & & & \Div\bfH  &= 0 \\
		\Curl\bfE &= -\mu_0\frac{\partial\bfH}{\partial t} & & & & & 
		\Curl\bfH &= \varepsilon_0\frac{\partial\bfE}{\partial t}
  	\end{aligned}
\end{equation}
To consider Electric and Magnetic field as as time-harmonic (time variation is sinusoidal) fields with angular frequency of $\omega$, which has the form of $\mathbf{\hat{u}} = \mathbf{u}e^{-i\omega t}$, the \textit{Maxwell equation} become,
\begin{equation}
	\begin{aligned}
		\Div\bfE  &= 0 & & & & & \Div\bfH  &= 0 \\
		\Curl\bfE &= i\omega\mu_0\bfH & & & & & 
		\Curl\bfH &= -i\omega\varepsilon_0\bfE \label{eq:nabla}
	\end{aligned}
\end{equation}
Take the curl of (\ref{eq:nabla}), 
\begin{equation}
	\begin{aligned}
		\Curl(\Curl\bfE) &= i\omega\mu_0(\Curl\bfH) = \omega^2\mu_0\varepsilon_0\bfE \\
		\Curl(\Curl\bfH) &= -i\omega\varepsilon_0(\Curl\bfE) = \omega^2\mu_0\varepsilon_0\bfH
	\end{aligned}
\end{equation}
If we use the rule \emph{Curl of Curl}, the \textit{Maxwell equations} reduce to the Helmholtz equations,
\begin{equation}
	\begin{aligned}
		\nabla^2\bfE + k^2\bfE = 0 & & & & & 
		\nabla^2\bfH + k^2\bfH = 0
	\end{aligned}
\end{equation}
where $k = \omega/c$, and $c=\frac{1}{\sqrt{\mu_0\varepsilon_0}}$ is the light speed in vacuum. 


\section{Bayesian Inference}
Bayesian inference is a paradigm for constructing statistical models based on Bayes’ Theorem
\begin{equation}
	p(\bmtheta|\bfX) = \frac{p(\bfX|\bmtheta)p(\bmtheta)}{p(\bfX)} \propto p(\bfX|\bmtheta)p(\bmtheta)
\end{equation}
Generally speaking, the goal of Bayesian inference is to estimate the posterior distribution ($p(\bmtheta|\bfX)$) given the likelihood ($p(\bfX|\bmtheta)$) and the prior distribution ($p(\bmtheta)$). The likelihood is something that can be estimated from the training data. 

\subsection{Maximum a Posteriori (MAP)}
In most of cases, we actually seek to maximize the posterior distribution which takes the existing data as fixed and determines the probability of any parameter setting $\bmtheta$ given that data $\bfX$. We call this process \emph{Maximum a Posteriori} (MAP), an iterative process which updates the model’s parameters in an attempt to maximize the probability of matching data to its distribution. Which is exactly the training pocess in a regular machine learning model.

MAP estimates can be computed via numerical optimization such as the conjugate gradient method or Newton's method. This usually requires first or second derivatives, which have to be evaluated analytically or numerically.

\subsection{Markov Chain Monte Carlo (MCMC)}
While MAP is the first step towards fully Bayesian inference, it’s still only computing what statisticians called a \emph{point estimate}. The downside of point estimates is that they don’t tell you much about a parameter other than its optimal setting. In reality, we often want to know other information, like how certain we are that a parameter’s value should fall within this predefined range. Therefore, a number of fascinating Bayesian methods have been devised that can be used to sample (i.e. draw sample values) from the posterior distribution. The most famous of these is an algorithm called \emph{Markov Chain Monte Carlo} (MCMC).

In statistics, MCMC methods comprise a class of algorithms for sampling from a probability distribution. By constructing a Markov chain that has the desired distribution as its equilibrium distribution, one can obtain a sample of the desired distribution by recording states from the chain. The more steps are included, the more closely the distribution of the sample matches the actual desired distribution. 

MCMC is used to simulate physical systems with Gibbs canonical distribution (\textbf{we will start to use $\bfx$ instead of $\bmtheta$ from here}):
\begin{equation}
	p(\bfx) \propto \exp\left( - \frac{U(\bfx)}{T} \right)
\end{equation}
Probability $p(\bfx)$ of a system to be in the state $\bfx$ depends on the energy of the state $U(\bfx)$ and temperature $T$.
Any distribution can be rewritten as Gibbs canonical distribution, but for many problems such energy-based distributions appear very naturally.
The goal becomes learning to sample from the canonical distribution.
System has higher probability of staying in the states with lower energies, so minimize energy is the same as maximum a posteriori.

\paragraph{Metropolis-Hastings (MH)} algorithm for MCMC is the simplest Markov Chain process that can sample from the distribution picks the neighbour of the current state and either accepts it or rejects depending on the change in energy. 
Algorithm produces a chain of states: $ \bfx_1, \bfx_2, ..., \bfx_n $. Each time a candidate from a neighborhood of the last state is selected
$\bfx_n' = \bfx_n + \varepsilon$ ($\epsilon$ is usually taken to be Gaussian with some spread $\sigma$).
With probability $p = \min \left[1, \exp\left( \frac{U(\bfx_n) - U(\bfx_n')}{T} \right) \right]$, system accepts new state (jumps to the new state):
$\bfx_{n+1} = \bfx_n'$ and with probability $1-p$ new state is rejected: $\bfx_{n+1} = \bfx_n$.
Note, when energy is lower in new state $U(\bfx'_n) < U(\bfx_n)$, it is always accepted: $p=1$.
In this way, we give preference to the states with lower energies, while not restricting the algorithm to always decrease the energy.
The lower temperature, the lower probability to increase energy.

Sampling high-dimensional distributions with MH becomes very inefficient in practice. A more efficient scheme is

\paragraph{Hamiltonian Monte Carlo (HMC)} algorithm, is also known as Hybrid Monte Carlo. Velocity $v$ is added to the parameters describing the system. Energy of the system consists of potential and kinetic parts:	$E(\bfx, \bfv) = U(\bfx) + K(\bfv)$. %$\qquad K(\bfv) = \sum_i \frac{m \, v^2_i}{2}$. 
Thus, velocities $\bfv$ and positions $\bfx$ have independent canonical distributions:
\begin{equation}
	p(\bfx, \bfv) \propto \exp\left(  \frac{-E(\bfx, \bfv)}{T}  \right)
	= \exp\left(  \frac{-U(\bfx)}{T}  \right) \, \exp \left( \frac{-K(\bfv)}{T} \right) \propto p(\bfx) \; p(\bfv).
\end{equation}
So once it can be sampled from joint distribution $p(\bfx, \bfv)$, $\bfx$ can be also sampled by ignoring computed velocities $\bfv$.
After initializing the system parameters $\bfx, \bfv$, it could be evolved using physics equations: $\dot{x}_i = v_i$, $m\dot{v_i} = -\frac{\partial U(\bfx)}{\partial x_i}$. During a long period of time, it will not get a canonical distribution by collecting system states, because energy $E$ is conserved in the system.
At some points, velocity is resampled from $p(\bfv)$, thus changing the total energy and resample the parameters. Sampling from $p(\bfv)$ is very simple, because $\bfv$ is normally distributed.

HMC uses not only energy $U(\bfx)$, but also it's gradient. So the `price' of a single iteration is higher, but HMC is still significantly more efficient than MH.
In most cases HMC accepts new states, but still, it has problems with sampling from distributions with isolated local minimum and discrete parameters (no gradient provided).

\paragraph{Metropolis-Adjusted Langevin Algorithm (MALA)} is based on \emph{Langevin Monte Carlo} (LMC). Different from gradient-based HMC, LMC uses a discrete Markov chain, which is equivalent to a gradient ascent procedure with injected Gaussian noise \cite{luan2020langevin}. The injected noise prevents the chain from collapsing to just the (local) maximum. Due to discretization error, the Markov chain is not guaranteed to converge to the same stationary distribution as the continuous process.
This can be corrected by using the Metropolis-Hasting rule to accept or reject states of the chain. This approach, known as the \emph{Metropolis-adjusted
Langevin algorithm} (MALA).

%\section{Notation}
%\input{tex/related/tab/alpha}


